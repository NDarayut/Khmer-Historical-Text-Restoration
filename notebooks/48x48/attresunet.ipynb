{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b255ba5c-acd4-4e12-b4e7-aee4305465b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "##############################################\n",
    "# 1. Define Basic Building Blocks\n",
    "##############################################\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Gate as in Attention U-Net.\n",
    "    g: gating signal (from decoder, coarser features)\n",
    "    x: skip connection features (from encoder, finer features)\n",
    "    \"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionGate, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        # Multiply attention coefficients with the encoder features\n",
    "        return x * psi\n",
    "\n",
    "##############################################\n",
    "# 2. Define the Attention Residual U-Net\n",
    "##############################################\n",
    "\n",
    "class AttentionResidualUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        \"\"\"\n",
    "        A simplified U-Net with residual blocks and attention gates on skip connections.\n",
    "        \"\"\"\n",
    "        super(AttentionResidualUNet, self).__init__()\n",
    "        self.encoder_blocks = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder: create residual blocks and save skip connection outputs\n",
    "        prev_channels = in_channels\n",
    "        for feature in features:\n",
    "            self.encoder_blocks.append(ResidualBlock(prev_channels, feature))\n",
    "            prev_channels = feature\n",
    "        \n",
    "        # Bottleneck: an extra residual block\n",
    "        self.bottleneck = ResidualBlock(features[-1], features[-1]*2)\n",
    "        \n",
    "        # Decoder: upsampling layers, attention gates, and residual blocks\n",
    "        self.upconv_blocks = nn.ModuleList()\n",
    "        self.decoder_blocks = nn.ModuleList()\n",
    "        self.attention_gates = nn.ModuleList()\n",
    "        rev_features = features[::-1]\n",
    "        decoder_in_channels = features[-1]*2\n",
    "        for feature in rev_features:\n",
    "            self.upconv_blocks.append(\n",
    "                nn.ConvTranspose2d(decoder_in_channels, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            # Attention gate: gating signal from decoder and skip connection from encoder\n",
    "            self.attention_gates.append(\n",
    "                AttentionGate(F_g=feature, F_l=feature, F_int=feature // 2)\n",
    "            )\n",
    "            # After concatenation, channels double\n",
    "            self.decoder_blocks.append(\n",
    "                ResidualBlock(feature * 2, feature)\n",
    "            )\n",
    "            decoder_in_channels = feature\n",
    "        \n",
    "        # Final convolution to get desired output channels\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for enc in self.encoder_blocks:\n",
    "            x = enc(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]  # reverse for decoder\n",
    "        \n",
    "        for idx in range(len(self.upconv_blocks)):\n",
    "            x = self.upconv_blocks[idx](x)\n",
    "            skip_connection = skip_connections[idx]\n",
    "            # Apply attention gate on skip connection features\n",
    "            att_gate = self.attention_gates[idx]\n",
    "            skip_connection = att_gate(g=x, x=skip_connection)\n",
    "            # Concatenate skip connection features with upsampled features\n",
    "            x = torch.cat([skip_connection, x], dim=1)\n",
    "            x = self.decoder_blocks[idx](x)\n",
    "        \n",
    "        return torch.sigmoid(self.final_conv(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02386b05-67d2-4430-8e53-fc566e00e571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting torchsummary\n",
      "  Using cached torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.11/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary, opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.11.0.86 torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless torchsummary # For install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dae8d6c-6eac-4e6d-bf3a-77344c068d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "AttentionResidualUNet                    [1, 1, 64, 64]            --\n",
       "├─ModuleList: 1-7                        --                        (recursive)\n",
       "│    └─ResidualBlock: 2-1                [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 64, 64]           576\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 64, 64]           128\n",
       "│    │    └─Sequential: 3-6              [1, 64, 64, 64]           192\n",
       "│    │    └─ReLU: 3-7                    [1, 64, 64, 64]           --\n",
       "├─MaxPool2d: 1-2                         [1, 64, 32, 32]           --\n",
       "├─ModuleList: 1-7                        --                        (recursive)\n",
       "│    └─ResidualBlock: 2-2                [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-8                  [1, 128, 32, 32]          73,728\n",
       "│    │    └─BatchNorm2d: 3-9             [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-10                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-11                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-12            [1, 128, 32, 32]          256\n",
       "│    │    └─Sequential: 3-13             [1, 128, 32, 32]          8,448\n",
       "│    │    └─ReLU: 3-14                   [1, 128, 32, 32]          --\n",
       "├─MaxPool2d: 1-4                         [1, 128, 16, 16]          --\n",
       "├─ModuleList: 1-7                        --                        (recursive)\n",
       "│    └─ResidualBlock: 2-3                [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-15                 [1, 256, 16, 16]          294,912\n",
       "│    │    └─BatchNorm2d: 3-16            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-17                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-18                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-19            [1, 256, 16, 16]          512\n",
       "│    │    └─Sequential: 3-20             [1, 256, 16, 16]          33,280\n",
       "│    │    └─ReLU: 3-21                   [1, 256, 16, 16]          --\n",
       "├─MaxPool2d: 1-6                         [1, 256, 8, 8]            --\n",
       "├─ModuleList: 1-7                        --                        (recursive)\n",
       "│    └─ResidualBlock: 2-4                [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-22                 [1, 512, 8, 8]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-23            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-24                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-25                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-26            [1, 512, 8, 8]            1,024\n",
       "│    │    └─Sequential: 3-27             [1, 512, 8, 8]            132,096\n",
       "│    │    └─ReLU: 3-28                   [1, 512, 8, 8]            --\n",
       "├─MaxPool2d: 1-8                         [1, 512, 4, 4]            --\n",
       "├─ResidualBlock: 1-9                     [1, 1024, 4, 4]           --\n",
       "│    └─Conv2d: 2-5                       [1, 1024, 4, 4]           4,718,592\n",
       "│    └─BatchNorm2d: 2-6                  [1, 1024, 4, 4]           2,048\n",
       "│    └─ReLU: 2-7                         [1, 1024, 4, 4]           --\n",
       "│    └─Conv2d: 2-8                       [1, 1024, 4, 4]           9,437,184\n",
       "│    └─BatchNorm2d: 2-9                  [1, 1024, 4, 4]           2,048\n",
       "│    └─Sequential: 2-10                  [1, 1024, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-29                 [1, 1024, 4, 4]           524,288\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 1024, 4, 4]           2,048\n",
       "│    └─ReLU: 2-11                        [1, 1024, 4, 4]           --\n",
       "├─ModuleList: 1-19                       --                        (recursive)\n",
       "│    └─ConvTranspose2d: 2-12             [1, 512, 8, 8]            2,097,664\n",
       "├─ModuleList: 1-20                       --                        (recursive)\n",
       "│    └─AttentionGate: 2-13               [1, 512, 8, 8]            --\n",
       "│    │    └─Sequential: 3-31             [1, 256, 8, 8]            131,840\n",
       "│    │    └─Sequential: 3-32             [1, 256, 8, 8]            131,840\n",
       "│    │    └─ReLU: 3-33                   [1, 256, 8, 8]            --\n",
       "│    │    └─Sequential: 3-34             [1, 1, 8, 8]              259\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─ResidualBlock: 2-14               [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-35                 [1, 512, 8, 8]            4,718,592\n",
       "│    │    └─BatchNorm2d: 3-36            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-37                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-38                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-39            [1, 512, 8, 8]            1,024\n",
       "│    │    └─Sequential: 3-40             [1, 512, 8, 8]            525,312\n",
       "│    │    └─ReLU: 3-41                   [1, 512, 8, 8]            --\n",
       "├─ModuleList: 1-19                       --                        (recursive)\n",
       "│    └─ConvTranspose2d: 2-15             [1, 256, 16, 16]          524,544\n",
       "├─ModuleList: 1-20                       --                        (recursive)\n",
       "│    └─AttentionGate: 2-16               [1, 256, 16, 16]          --\n",
       "│    │    └─Sequential: 3-42             [1, 128, 16, 16]          33,152\n",
       "│    │    └─Sequential: 3-43             [1, 128, 16, 16]          33,152\n",
       "│    │    └─ReLU: 3-44                   [1, 128, 16, 16]          --\n",
       "│    │    └─Sequential: 3-45             [1, 1, 16, 16]            131\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─ResidualBlock: 2-17               [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-46                 [1, 256, 16, 16]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-47            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-48                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-49                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-50            [1, 256, 16, 16]          512\n",
       "│    │    └─Sequential: 3-51             [1, 256, 16, 16]          131,584\n",
       "│    │    └─ReLU: 3-52                   [1, 256, 16, 16]          --\n",
       "├─ModuleList: 1-19                       --                        (recursive)\n",
       "│    └─ConvTranspose2d: 2-18             [1, 128, 32, 32]          131,200\n",
       "├─ModuleList: 1-20                       --                        (recursive)\n",
       "│    └─AttentionGate: 2-19               [1, 128, 32, 32]          --\n",
       "│    │    └─Sequential: 3-53             [1, 64, 32, 32]           8,384\n",
       "│    │    └─Sequential: 3-54             [1, 64, 32, 32]           8,384\n",
       "│    │    └─ReLU: 3-55                   [1, 64, 32, 32]           --\n",
       "│    │    └─Sequential: 3-56             [1, 1, 32, 32]            67\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─ResidualBlock: 2-20               [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-57                 [1, 128, 32, 32]          294,912\n",
       "│    │    └─BatchNorm2d: 3-58            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-59                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-60                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-61            [1, 128, 32, 32]          256\n",
       "│    │    └─Sequential: 3-62             [1, 128, 32, 32]          33,024\n",
       "│    │    └─ReLU: 3-63                   [1, 128, 32, 32]          --\n",
       "├─ModuleList: 1-19                       --                        (recursive)\n",
       "│    └─ConvTranspose2d: 2-21             [1, 64, 64, 64]           32,832\n",
       "├─ModuleList: 1-20                       --                        (recursive)\n",
       "│    └─AttentionGate: 2-22               [1, 64, 64, 64]           --\n",
       "│    │    └─Sequential: 3-64             [1, 32, 64, 64]           2,144\n",
       "│    │    └─Sequential: 3-65             [1, 32, 64, 64]           2,144\n",
       "│    │    └─ReLU: 3-66                   [1, 32, 64, 64]           --\n",
       "│    │    └─Sequential: 3-67             [1, 1, 64, 64]            35\n",
       "├─ModuleList: 1-21                       --                        (recursive)\n",
       "│    └─ResidualBlock: 2-23               [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-68                 [1, 64, 64, 64]           73,728\n",
       "│    │    └─BatchNorm2d: 3-69            [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-70                   [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-71                 [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-72            [1, 64, 64, 64]           128\n",
       "│    │    └─Sequential: 3-73             [1, 64, 64, 64]           8,320\n",
       "│    │    └─ReLU: 3-74                   [1, 64, 64, 64]           --\n",
       "├─Conv2d: 1-22                           [1, 1, 64, 64]            65\n",
       "==========================================================================================\n",
       "Total params: 32,786,605\n",
       "Trainable params: 32,786,605\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 3.64\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 59.89\n",
       "Params size (MB): 131.15\n",
       "Estimated Total Size (MB): 191.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# Initialize the model\n",
    "model = AttentionResidualUNet(in_channels=1, out_channels=1)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(1, 1, 64, 64), device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29ab9f0-a8c9-4431-87e0-1c2b7719dfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /opt/conda/lib/python3.11/site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f83c1ba-313e-46c7-b1c7-04fa322aef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches: 187150\n",
      "Using device: cuda\n",
      "GPU available: NVIDIA A10G\n",
      "Epoch 1/10\n",
      "Batch 0/2925 - Loss: 0.2639\n",
      "    GPU Memory Usage: 666.25 MB\n",
      "Batch 1000/2925 - Loss: 0.0111\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0183\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [1/10] completed in 233.46s\n",
      "Average Loss: 0.0228\n",
      "--------------------------------------------------\n",
      "Epoch 2/10\n",
      "Batch 0/2925 - Loss: 0.0210\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 1000/2925 - Loss: 0.0061\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0178\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [2/10] completed in 218.90s\n",
      "Average Loss: 0.0165\n",
      "--------------------------------------------------\n",
      "Epoch 3/10\n",
      "Batch 0/2925 - Loss: 0.0113\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 1000/2925 - Loss: 0.0043\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0172\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [3/10] completed in 194.40s\n",
      "Average Loss: 0.0151\n",
      "--------------------------------------------------\n",
      "Epoch 4/10\n",
      "Batch 0/2925 - Loss: 0.0093\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 1000/2925 - Loss: 0.0034\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0167\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [4/10] completed in 194.41s\n",
      "Average Loss: 0.0142\n",
      "--------------------------------------------------\n",
      "Epoch 5/10\n",
      "Batch 0/2925 - Loss: 0.0014\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 1000/2925 - Loss: 0.0030\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0152\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [5/10] completed in 194.40s\n",
      "Average Loss: 0.0133\n",
      "--------------------------------------------------\n",
      "Epoch 6/10\n",
      "Batch 0/2925 - Loss: 0.0028\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 1000/2925 - Loss: 0.0025\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0136\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [6/10] completed in 194.41s\n",
      "Average Loss: 0.0122\n",
      "--------------------------------------------------\n",
      "Epoch 7/10\n",
      "Batch 0/2925 - Loss: 0.0012\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 1000/2925 - Loss: 0.0022\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0120\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [7/10] completed in 194.41s\n",
      "Average Loss: 0.0110\n",
      "--------------------------------------------------\n",
      "Epoch 8/10\n",
      "Batch 0/2925 - Loss: 0.0007\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 1000/2925 - Loss: 0.0023\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0108\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [8/10] completed in 194.42s\n",
      "Average Loss: 0.0098\n",
      "--------------------------------------------------\n",
      "Epoch 9/10\n",
      "Batch 0/2925 - Loss: 0.0008\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 1000/2925 - Loss: 0.0021\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0095\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [9/10] completed in 194.42s\n",
      "Average Loss: 0.0087\n",
      "--------------------------------------------------\n",
      "Epoch 10/10\n",
      "Batch 0/2925 - Loss: 0.0008\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 1000/2925 - Loss: 0.0019\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Batch 2000/2925 - Loss: 0.0089\n",
      "    GPU Memory Usage: 667.82 MB\n",
      "Epoch [10/10] completed in 194.49s\n",
      "Average Loss: 0.0079\n",
      "--------------------------------------------------\n",
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "# Fix random seeds for reproducibility\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        \"\"\"\n",
    "        Dataset for loading pre-extracted patches.\n",
    "        \"\"\"\n",
    "        self.original_patches = np.load(os.path.join(data_path, 'original_patches.npy')) # Original patch\n",
    "        self.ground_truth_patches = np.load(os.path.join(data_path, 'ground_truth_patches.npy')) # Ground truth patch\n",
    "        self.num_samples = len(self.original_patches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_patch = self.original_patches[idx]\n",
    "        ground_truth_patch = self.ground_truth_patches[idx]\n",
    "\n",
    "        # Convert to tensors and normalize to [0, 1]\n",
    "        original_patch = torch.tensor(original_patch, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "        ground_truth_patch = torch.tensor(ground_truth_patch, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "\n",
    "        return original_patch, ground_truth_patch\n",
    "\n",
    "# Initialize the dataset\n",
    "train_data_path = 'data/train_patches_64x64x25'\n",
    "train_dataset = PatchDataset(train_data_path)\n",
    "\n",
    "# Define a seed\n",
    "seed = 1\n",
    "\n",
    "# Worker initialization function\n",
    "def worker_init_fn(worker_id):\n",
    "    # Seed each worker with a combination of the base seed and the worker ID\n",
    "    np.random.seed(seed + worker_id)\n",
    "    torch.manual_seed(seed + worker_id)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False, # Need continous context\n",
    "    num_workers=6,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=worker_init_fn\n",
    ")\n",
    "\n",
    "# Model setup (example: AttU_Net)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AttentionResidualUNet(in_channels=1, out_channels=1).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "scaler = amp.GradScaler()\n",
    "\n",
    "print(f\"Total patches: {len(train_dataset)}\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for batch_idx, (original_patches, ground_truth_patches) in enumerate(train_loader):\n",
    "        inputs = original_patches.to(device)\n",
    "        targets = ground_truth_patches.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with mixed precision\n",
    "        with amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backpropagation with mixed precision\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Batch progress and memory usage\n",
    "        if batch_idx % 1000 == 0:  # Log every 1000 batches\n",
    "            print(f\"Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "            if device.type == 'cuda':\n",
    "                gpu_memory = torch.cuda.memory_allocated(device) / 1e6  # Convert to MB\n",
    "                print(f\"    GPU Memory Usage: {gpu_memory:.2f} MB\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] completed in {epoch_time:.2f}s\")\n",
    "    print(f\"Average Loss: {epoch_loss:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs('model', exist_ok=True)\n",
    "torch.save(model.state_dict(), 'model_64x64x25/attresunet_trained_64x64x25.pth')\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eefe5c1-8aca-411c-b3b9-67eef354faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 0.0399\n",
      "Average PSNR: 21.9758 dB\n",
      "Average SSIM: 0.8463\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage import img_as_ubyte\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "model = AttentionResidualUNet(in_channels=1, out_channels=1).to(device)\n",
    "model.load_state_dict(torch.load('model_64x64x25/attresunet_trained_64x64x25.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Define the dataset and DataLoader\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        \"\"\"\n",
    "        Dataset for loading pre-extracted patches.\n",
    "        \"\"\"\n",
    "        self.original_patches = np.load(os.path.join(data_path, 'original_patches.npy'))\n",
    "        self.ground_truth_patches = np.load(os.path.join(data_path, 'ground_truth_patches.npy'))\n",
    "        self.num_samples = len(self.original_patches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_patch = self.original_patches[idx]\n",
    "        ground_truth_patch = self.ground_truth_patches[idx]\n",
    "        # Convert to tensors and normalize to [0, 1]\n",
    "        original_patch = torch.tensor(original_patch, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "        ground_truth_patch = torch.tensor(ground_truth_patch, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "        return original_patch, ground_truth_patch\n",
    "\n",
    "# Helper function for SSIM (using skimage)\n",
    "def calculate_ssim_custom(output, target):\n",
    "    output_np = output.squeeze().cpu().numpy()\n",
    "    target_np = target.squeeze().cpu().numpy()\n",
    "    output_np = img_as_ubyte(np.clip(output_np, 0, 1))\n",
    "    target_np = img_as_ubyte(np.clip(target_np, 0, 1))\n",
    "    return ssim(output_np, target_np, data_range=255.0)\n",
    "\n",
    "##############################################\n",
    "# Custom MSE and PSNR Functions from Scratch\n",
    "##############################################\n",
    "\n",
    "def calculate_mse(output, target):\n",
    "    \"\"\"\n",
    "    Compute the Mean Squared Error between two images.\n",
    "    Args:\n",
    "        output (np.ndarray): The output image.\n",
    "        target (np.ndarray): The ground truth image.\n",
    "    Returns:\n",
    "        float: The MSE value.\n",
    "    \"\"\"\n",
    "    return np.mean((output - target) ** 2)\n",
    "\n",
    "def calculate_psnr_from_scratch(output, target, max_pixel=1.0):\n",
    "    \"\"\"\n",
    "    Compute the Peak Signal-to-Noise Ratio using MSE.\n",
    "    Args:\n",
    "        output (np.ndarray): The output image.\n",
    "        target (np.ndarray): The ground truth image.\n",
    "        max_pixel (float): The maximum possible pixel value (default: 1.0 for normalized images).\n",
    "    Returns:\n",
    "        float: The PSNR value in decibels.\n",
    "    \"\"\"\n",
    "    mse_value = calculate_mse(output, target)\n",
    "    if mse_value == 0:\n",
    "        return float('inf')\n",
    "    return 10 * math.log10((max_pixel ** 2) / mse_value)\n",
    "\n",
    "##############################################\n",
    "# Evaluation on Test Data\n",
    "##############################################\n",
    "\n",
    "data_path = 'data/test_patches_64x64x25'\n",
    "patch_dataset = PatchDataset(data_path)\n",
    "patch_loader = DataLoader(patch_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Metrics storage and image reconstruction\n",
    "mse_list = []\n",
    "psnr_list = []\n",
    "ssim_list = []\n",
    "reconstructed_patches = []\n",
    "\n",
    "for i, (original_patch, ground_truth_patch) in enumerate(patch_loader):\n",
    "    original_patch = original_patch.to(device)\n",
    "    ground_truth_patch = ground_truth_patch.to(device)\n",
    "\n",
    "    # Predict the output from the model\n",
    "    with torch.no_grad():\n",
    "        output_patch = model(original_patch)\n",
    "\n",
    "    # Convert tensors to numpy arrays for metric calculations\n",
    "    output_np = output_patch.squeeze().cpu().numpy()\n",
    "    ground_truth_np = ground_truth_patch.squeeze().cpu().numpy()\n",
    "\n",
    "    # Calculate MSE using our custom function\n",
    "    mse_value = calculate_mse(output_np, ground_truth_np)\n",
    "    \n",
    "    # Calculate PSNR using our custom function\n",
    "    psnr_value = calculate_psnr_from_scratch(output_np, ground_truth_np, max_pixel=1.0)\n",
    "    \n",
    "    # Calculate SSIM\n",
    "    ssim_value = calculate_ssim_custom(output_patch, ground_truth_patch)\n",
    "    \n",
    "    mse_list.append(mse_value)\n",
    "    psnr_list.append(psnr_value)\n",
    "    ssim_list.append(ssim_value)\n",
    "    \n",
    "    # Collect patches for reconstruction if needed\n",
    "    reconstructed_patches.append(output_np)\n",
    "\n",
    "# Calculate and print the average metrics\n",
    "average_mse = np.mean(mse_list)\n",
    "average_psnr = np.mean(psnr_list)\n",
    "average_ssim = np.mean(ssim_list)\n",
    "\n",
    "print(f\"Average MSE: {average_mse:.4f}\")\n",
    "print(f\"Average PSNR: {average_psnr:.4f} dB\")\n",
    "print(f\"Average SSIM: {average_ssim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a1b30-32cd-4520-8658-2d8ff497267a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
